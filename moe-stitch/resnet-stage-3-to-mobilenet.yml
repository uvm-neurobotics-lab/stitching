#
# Replace ResNet-50 Stage 3 with MobileNetV3-Large Stage 3.
#  - resnet50.a1_in1k:                            80.4% (ResNet Strikes Back A1 recipe)
#  - resnet50.fb_swsl_ig1b_ft_in1k (alternative): 81.1% (SWSL Self-Supervised Pre-Training)
#  - mobilenetv3_large_100.ra_in1k:               75.8% (RandAugment recipe)
#  - mobilenetv3_large_100.miil_in21k_ft_in1k:    77.9% (Pretrained on IN-21k, then fine-tuned on IN-1k)


assembly:
  - Subnet:
      frozen: true
      backend: timm
      model_name: resnet50.a1_in1k
      block_input: x
      in_format: img
      block_output: layer3.0
      out_format: [img, [1024, 14, 14]]
  - ResNetBottleneck:
      frozen: false
      in_channels: 1024
      out_channels: 80
  - Subnet:
      frozen: true
      backend: timm
      model_name: mobilenetv3_large_100.ra_in1k
      block_input: blocks.3.1
      block_output: blocks.4.1
      in_format: [img, [80, 14, 14]]
      out_format: [img, [112, 14, 14]]
  - ResNetBottleneck:
      frozen: false
      in_channels: 112
      out_channels: 1024
  - Subnet:
      frozen: true
      backend: timm
      model_name: resnet50.a1_in1k
      block_input: layer4.0
      in_format: [img, [1024, 14, 14]]
      block_output: fc
      out_format: vector

deterministic: false
eval_checkpoints: true
save_checkpoints: false

train_config:
  batch_size: 256
  data_augmentation: true
  dataset: imagenet
  epochs: 10
  loss_fn: cross_entropy
  lr_scheduler: CosineAnnealingLR
  lr_scheduler_args:
    T_max: 10
    eta_min: 0.0
  max_grad_norm: 0
  optimizer: AdamW
  optimizer_args:
    lr: 0.002
    weight_decay: 0.05
